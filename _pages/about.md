---
layout: about
title: about
permalink: /
subtitle: <b>Doctoral Candidate</b> @ <a href="https://www.umu.se/en/research/groups/xai--explainable-ai/">Umeå universitet</a> &#x2022; <b>MSc</b> from <a href="https://www.ucl.ac.uk/bartlett/casa/bartlett-centre-advanced-spatial-analysis/">University College London</a>


profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >


news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi, I'm Minal!

I am currently pursuing a doctorate degree in computer science at [Umeå universitet](https://www.umu.se/en/department-of-computing-science/) advised by [Kary Främling](https://www.umu.se/en/staff/kary-framling/). My PhD is in collaboration and funded by Sweden's national initiative project [Wallenberg AI, Autonomous Systems and Software Program(WASP)](https://wasp-sweden.org/) and [Knut and Alice Wallenberg Foundation (KAW)](https://kaw.wallenberg.org/en).

Machine learning has made significant progress on System 1 (from Daniel Kahneman's book "Thinking, Fast and Slow") functionality - behaviours that are quick, spontaneous, and unconscious—such as object recognition, interpreting basic words, and driving vehicles in ideal roadways. Nonetheless, it still has challenges with System 2 abilities, which typically entail systematic, logical, and conscious reasoning such as programming or solving math problems. To address this, my research seeks to establish intelligent systems that reason in a precise, consistent, verifiable and interpretable manner in real-life situations. 

My research interests lie at the intersection between Formal Methods and Software Engineering, particularly in applying formal methods to software systems with components generated via machine learning. 

My research is also focussed on addressing societal concerns pertinent to algorithm-led decisions in the public and private sector:

- What are the implications of issues around algorithmic transparency and explainability?
- How can we guarantee machine learning models and their explanations are robust to adversarial attacks?
- How do we check datasets for bias or incompleteness, and how do we tackle these where we find them?

<!-- You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. 

Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.
-->
